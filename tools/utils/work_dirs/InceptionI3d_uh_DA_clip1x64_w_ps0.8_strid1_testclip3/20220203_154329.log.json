{"env_info": "sys.platform: linux\nPython: 3.6.13 |Anaconda, Inc.| (default, Jun  4 2021, 14:25:59) [GCC 7.5.0]\nCUDA available: True\nGPU 0: NVIDIA GeForce RTX 2080 Ti\nGPU 1: NVIDIA GeForce GT 1030\nCUDA_HOME: /usr/local/cuda\nNVCC: Cuda compilation tools, release 10.0, V10.0.130\nGCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\nPyTorch: 1.7.1\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 10.1\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n  - CuDNN 7.6.3\n  - Magma 2.5.2\n  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n\nTorchVision: 0.8.2\nOpenCV: 3.4.0\nMMCV: 1.4.0\nMMCV Compiler: n/a\nMMCV CUDA Compiler: n/a\nMMAction2: 0.20.0+2b6f9ac", "seed": null, "config_name": "i3d_incep_da_kinetics400_rgb_video_1x64_strid1_test3clip_64d_w_ps0.8.py", "work_dir": "InceptionI3d_uh_DA_clip1x64_w_ps0.8_strid1_testclip3"}
{"mode": "train", "epoch": 1, "iter": 20, "lr": 0.001, "memory": 3675, "data_time": 0.31419, "loss_cls_clip_t": 2.50213, "top1_acc_clip_t": 7.5, "loss_cls_clip_t_ps": 2.5135, "loss": 2.5135, "grad_norm": 1.80104, "time": 0.70376}
{"mode": "train", "epoch": 1, "iter": 40, "lr": 0.001, "memory": 3675, "data_time": 0.22849, "loss_cls_clip_t": 2.44979, "top1_acc_clip_t": 10.0, "loss_cls_clip_t_ps": 2.44399, "loss": 2.44399, "grad_norm": 1.75686, "time": 0.61021}
{"mode": "train", "epoch": 1, "iter": 60, "lr": 0.001, "memory": 3675, "data_time": 0.24443, "loss_cls_clip_t": 2.49042, "top1_acc_clip_t": 15.0, "loss_cls_clip_t_ps": 2.43703, "loss": 2.43703, "grad_norm": 2.126, "time": 0.62729}
{"mode": "train", "epoch": 1, "iter": 80, "lr": 0.001, "memory": 3675, "data_time": 0.25219, "loss_cls_clip_t": 2.47607, "top1_acc_clip_t": 5.0, "loss_cls_clip_t_ps": 2.31605, "loss": 2.31605, "grad_norm": 2.38982, "time": 0.63695}
{"mode": "train", "epoch": 1, "iter": 100, "lr": 0.001, "memory": 3675, "data_time": 0.21744, "loss_cls_clip_t": 2.38394, "top1_acc_clip_t": 12.5, "loss_cls_clip_t_ps": 2.37951, "loss": 2.37951, "grad_norm": 2.40695, "time": 0.59905}
{"mode": "train", "epoch": 1, "iter": 120, "lr": 0.001, "memory": 3675, "data_time": 0.23448, "loss_cls_clip_t": 2.48942, "top1_acc_clip_t": 2.5, "loss_cls_clip_t_ps": 2.48529, "loss": 2.48529, "grad_norm": 2.49167, "time": 0.6193}
{"mode": "train", "epoch": 1, "iter": 140, "lr": 0.001, "memory": 3675, "data_time": 0.28164, "loss_cls_clip_t": 2.46308, "top1_acc_clip_t": 10.0, "loss_cls_clip_t_ps": 2.41915, "loss": 2.41915, "grad_norm": 2.55425, "time": 0.67434}
{"mode": "train", "epoch": 1, "iter": 160, "lr": 0.001, "memory": 3675, "data_time": 0.2551, "loss_cls_clip_t": 2.26706, "top1_acc_clip_t": 22.5, "loss_cls_clip_t_ps": 2.22585, "loss": 2.22585, "grad_norm": 2.75266, "time": 0.64389}
{"mode": "train", "epoch": 1, "iter": 180, "lr": 0.001, "memory": 3675, "data_time": 0.25305, "loss_cls_clip_t": 2.29167, "top1_acc_clip_t": 15.0, "loss_cls_clip_t_ps": 2.2221, "loss": 2.2221, "grad_norm": 3.68777, "time": 0.6431}
{"mode": "train", "epoch": 1, "iter": 200, "lr": 0.001, "memory": 3675, "data_time": 0.24898, "loss_cls_clip_t": 2.14466, "top1_acc_clip_t": 22.5, "loss_cls_clip_t_ps": 2.15277, "loss": 2.15277, "grad_norm": 3.66225, "time": 0.63919}
{"mode": "train", "epoch": 1, "iter": 220, "lr": 0.001, "memory": 3675, "data_time": 0.2572, "loss_cls_clip_t": 1.8599, "top1_acc_clip_t": 47.5, "loss_cls_clip_t_ps": 1.8599, "loss": 1.8599, "grad_norm": 4.21097, "time": 0.64735}
{"mode": "train", "epoch": 1, "iter": 240, "lr": 0.001, "memory": 3675, "data_time": 0.26573, "loss_cls_clip_t": 1.71367, "top1_acc_clip_t": 32.5, "loss_cls_clip_t_ps": 1.74498, "loss": 1.74498, "grad_norm": 5.23494, "time": 0.65416}
{"mode": "train", "epoch": 1, "iter": 260, "lr": 0.001, "memory": 3675, "data_time": 0.24117, "loss_cls_clip_t": 1.4809, "top1_acc_clip_t": 55.0, "loss_cls_clip_t_ps": 1.35379, "loss": 1.35379, "grad_norm": 6.01994, "time": 0.6276}
{"mode": "train", "epoch": 1, "iter": 280, "lr": 0.001, "memory": 3675, "data_time": 0.26944, "loss_cls_clip_t": 1.21831, "top1_acc_clip_t": 60.0, "loss_cls_clip_t_ps": 1.18868, "loss": 1.18868, "grad_norm": 7.30233, "time": 0.6622}
{"mode": "train", "epoch": 1, "iter": 300, "lr": 0.001, "memory": 3675, "data_time": 0.24913, "loss_cls_clip_t": 1.47445, "top1_acc_clip_t": 50.0, "loss_cls_clip_t_ps": 1.46917, "loss": 1.46917, "grad_norm": 8.22343, "time": 0.64062}
{"mode": "train", "epoch": 1, "iter": 320, "lr": 0.001, "memory": 3675, "data_time": 0.25438, "loss_cls_clip_t": 1.83304, "top1_acc_clip_t": 42.5, "loss_cls_clip_t_ps": 1.74722, "loss": 1.74722, "grad_norm": 6.49952, "time": 0.64518}
