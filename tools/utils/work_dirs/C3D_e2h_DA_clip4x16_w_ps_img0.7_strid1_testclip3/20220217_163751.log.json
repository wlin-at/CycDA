{"env_info": "sys.platform: linux\nPython: 3.6.13 |Anaconda, Inc.| (default, Jun  4 2021, 14:25:59) [GCC 7.5.0]\nCUDA available: True\nGPU 0: NVIDIA GeForce RTX 2080 Ti\nGPU 1: NVIDIA GeForce GT 1030\nCUDA_HOME: /usr/local/cuda\nNVCC: Cuda compilation tools, release 10.0, V10.0.130\nGCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\nPyTorch: 1.7.1\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 10.1\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n  - CuDNN 7.6.3\n  - Magma 2.5.2\n  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n\nTorchVision: 0.8.2\nOpenCV: 3.4.0\nMMCV: 1.4.0\nMMCV Compiler: n/a\nMMCV CUDA Compiler: n/a\nMMAction2: 0.20.0+2b6f9ac", "seed": null, "config_name": "c3d_da_rgb_video_1x64_strid1_test3clip_64d_w_ps_img0.7_targetonly_split1.py", "work_dir": "C3D_e2h_DA_clip4x16_w_ps_img0.7_strid1_testclip3"}
{"mode": "train", "epoch": 1, "iter": 20, "lr": 0.001, "memory": 2195, "data_time": 0.22582, "loss_cls_clip_t": 2.88403, "top1_acc_clip_t": 12.5, "loss_cls_clip_t_ps": 2.8584, "loss": 2.8584, "grad_norm": 21.3373, "time": 0.49367}
{"mode": "train", "epoch": 1, "iter": 40, "lr": 0.001, "memory": 2195, "data_time": 0.10974, "loss_cls_clip_t": 2.63621, "top1_acc_clip_t": 12.5, "loss_cls_clip_t_ps": 2.50786, "loss": 2.50786, "grad_norm": 3.84958, "time": 0.36604}
{"mode": "train", "epoch": 1, "iter": 60, "lr": 0.001, "memory": 2195, "data_time": 0.09959, "loss_cls_clip_t": 2.56172, "top1_acc_clip_t": 7.5, "loss_cls_clip_t_ps": 2.53236, "loss": 2.53236, "grad_norm": 2.21895, "time": 0.35612}
{"mode": "train", "epoch": 1, "iter": 80, "lr": 0.001, "memory": 2195, "data_time": 0.10964, "loss_cls_clip_t": 2.62677, "top1_acc_clip_t": 5.0, "loss_cls_clip_t_ps": 2.51143, "loss": 2.51143, "grad_norm": 0.96249, "time": 0.3669}
{"mode": "train", "epoch": 1, "iter": 100, "lr": 0.001, "memory": 2195, "data_time": 0.11099, "loss_cls_clip_t": 2.65688, "top1_acc_clip_t": 7.5, "loss_cls_clip_t_ps": 2.53615, "loss": 2.53615, "grad_norm": 1.59022, "time": 0.37063}
{"mode": "train", "epoch": 1, "iter": 120, "lr": 0.001, "memory": 2195, "data_time": 0.10445, "loss_cls_clip_t": 2.58922, "top1_acc_clip_t": 12.5, "loss_cls_clip_t_ps": 2.53289, "loss": 2.53289, "grad_norm": 1.57998, "time": 0.36256}
{"mode": "train", "epoch": 1, "iter": 140, "lr": 0.001, "memory": 2195, "data_time": 0.10014, "loss_cls_clip_t": 2.57357, "top1_acc_clip_t": 3.75, "loss_cls_clip_t_ps": 2.45464, "loss": 2.45464, "grad_norm": 2.64206, "time": 0.3581}
{"mode": "train", "epoch": 1, "iter": 160, "lr": 0.001, "memory": 2195, "data_time": 0.09742, "loss_cls_clip_t": 2.47801, "top1_acc_clip_t": 9.375, "loss_cls_clip_t_ps": 2.38369, "loss": 2.38369, "grad_norm": 2.34185, "time": 0.35597}
{"mode": "train", "epoch": 1, "iter": 180, "lr": 0.001, "memory": 2195, "data_time": 0.08709, "loss_cls_clip_t": 2.57167, "top1_acc_clip_t": 13.75, "loss_cls_clip_t_ps": 2.44457, "loss": 2.44457, "grad_norm": 4.60013, "time": 0.34638}
{"mode": "train", "epoch": 1, "iter": 200, "lr": 0.001, "memory": 2195, "data_time": 0.09528, "loss_cls_clip_t": 2.60603, "top1_acc_clip_t": 10.0, "loss_cls_clip_t_ps": 2.48269, "loss": 2.48269, "grad_norm": 1.07723, "time": 0.35512}
{"mode": "train", "epoch": 1, "iter": 220, "lr": 0.001, "memory": 2195, "data_time": 0.1241, "loss_cls_clip_t": 2.54588, "top1_acc_clip_t": 10.0, "loss_cls_clip_t_ps": 2.40275, "loss": 2.40275, "grad_norm": 1.07557, "time": 0.38528}
{"mode": "train", "epoch": 1, "iter": 240, "lr": 0.001, "memory": 2195, "data_time": 0.1095, "loss_cls_clip_t": 2.64676, "top1_acc_clip_t": 7.5, "loss_cls_clip_t_ps": 2.51313, "loss": 2.51313, "grad_norm": 1.24316, "time": 0.37103}
{"mode": "train", "epoch": 1, "iter": 260, "lr": 0.001, "memory": 2195, "data_time": 0.10363, "loss_cls_clip_t": 2.65917, "top1_acc_clip_t": 12.5, "loss_cls_clip_t_ps": 2.50028, "loss": 2.50028, "grad_norm": 1.11929, "time": 0.36647}
